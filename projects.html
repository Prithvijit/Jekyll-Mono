  <div class="row section_heading">
    <h2 align="center"><a href="#projects">Projects</a></h2>
    <div class="row">
      <div class="col-md-7">
        <h3 class="content_heading"><a target="_blank" href="http://evalai.cloudcv.org/">EvalAI</a></h3>
          <!-- <p class="">I worked under the guidance of <a href="https://filebox.ece.vt.edu/~parikh/">Dr. Devi Parikh</a> and <a href="https://filebox.ece.vt.edu/~dbatra/">Dr. Dhruv Batra</a>.</p>  -->
          <p class="">We designed an open source platform to help researchers, students and data scientists to host and participate in AI challenges. By simplifying and standardizing the process of benchmarking AI, EvalAI aims to circumvent many of the factors impeding the rate of progress in AI such as - standardized evaluation protocols, faster evaluation, etc.  Supported by CloudCV, EvalAI hosted the VQA Challenge at CVPR'17 with a 6x speedup in evaluation compared to the previous iteration of the challenge on CodaLab. Researchers from a number of organizations have shown interest in hosting their AI Challenges on EvalAI in the near future. Some of these organizations are: Facebook AI Research, Google Research, Stanford University, Georgia Tech, etc.</p>
          <!-- <p class=""><b>ArXiV Link : </b><a href="https://arxiv.org/pdf/1604.03505v2.pdf">https://arxiv.org/pdf/1604.03505v2.pdf</a></p> -->
      </div>

      <div class="col-md-5" align="center">
        <iframe width="100%" height="315" src="https://www.youtube.com/embed/gf8NnxK2B24" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>

    <div class="row">
      <div class="col-md-7">
        <h3 class="content_heading"><a target="_blank" href="https://arxiv.org/abs/1704.00717">Theory of AI's Mind</a></h3>
          <!-- <p class="">I worked under the guidance of <a href="https://filebox.ece.vt.edu/~parikh/">Dr. Devi Parikh</a> and <a href="https://filebox.ece.vt.edu/~dbatra/">Dr. Dhruv Batra</a>.</p>  -->
          <p class="">We argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks. We instantiate these ideas within the domain of Visual Question Answering (VQA). We find that using just a few examples (50), lay people can be trained to better predict responses and oncoming failures of a complex VQA model. We further evaluate the role of existing explanation (or interpretability) modalities play in helping humans build ToAIM. Our results indicate that existing explanation modalities do not make VQA models more <i>legible</i>.</p>
          <p class=""><b>ArXiV Link : </b><a href="https://arxiv.org/pdf/1704.00717.pdf">https://arxiv.org/pdf/1704.00717.pdf</a></p>
          <p class=""><b>Tasks : </b><a href="https://www.youtube.com/watch?v=Dcs7GOmTAns">Failure Prediction</a> and <a href="https://www.youtube.com/watch?v=f_1ikwCuG4Q">Knowledge Prediction</a></p>   
      </div>

      <div class="col-md-5" align="center">
        <img src="https://media.giphy.com/media/xUA7bc8XxUUpVP8tPy/giphy.gif" width="100%" style="margin-top: 100px;">
      </div>
    </div>


    <div class="row">
      <div class="col-md-7">
        <h3 class="content_heading"><a target="_blank" href="https://filebox.ece.vt.edu/~prithv1/counting.html">Counting Everyday Objects in Everyday Scenes</a></h3>
          <p class="">I worked with <a href="https://filebox.ece.vt.edu/~parikh/">Dr. Devi Parikh</a> and <a href="https://filebox.ece.vt.edu/~dbatra/">Dr. Dhruv Batra</a>.</p> 
          <p class="">We build dedicated models for counting designed to tackle the large variance in counts, appearances, and scales of objects found in natural scenes. Our approach is inspired by the phenomenon of subitizing - the ability of humans to make quick assessments of counts given a perceptual signal, for small count values. Given a natural scene, we employ a divide and conquer strategy while incorporating context across the scene to adapt the subitizing idea to counting. Subsequently, we study how counting can be used to improve object detection and show a proof of concept application of our counting methods to the task of Visual Question Answering.</p>
          <p class=""><b>ArXiV Link : </b><a href="https://arxiv.org/pdf/1604.03505v2.pdf">https://arxiv.org/pdf/1604.03505v2.pdf</a></p>
          <p class=""><b>Spotlight : </b><a href="http://cvpr2017.thecvf.com/">CVPR 2017</a></p>
      </div>

      <div class="col-md-5" align="center">
        <img src="static/img/seq_new.png" width="100%" style="margin-top: 100px;">
      </div>
    </div>

    <div class="row">
      <div class="col-md-7">
        <h3 class="content_heading"><a target="_blank" href="http://robotics.iiit.ac.in/uploads/Main/Publications/Siva_etal_ICVGIP_14.pdf">Guess from Far, Recognize when Near : Searching the Floor for Small Objects</a></h3>
          <p class="">I worked with <a href="http://faculty.iiit.ac.in/~mkrishna/">Dr. K. Madhava Krishna</a>.</p> 
          <p class="">We implemented an efficient strategy for a robot to explore, discover, recognize and navigate to a selected few objects among a number of objects scattered on the floor, based on guess from far and recognize from near strategy. From far away, we assign Existential Probabilities to the objects, indicating their similarity to queried objects. A Bayes’ Net is constructed over the probabilities, to overlay and orient a Viewpoint Object Potential(VOP) map over potential search objects. VOP quantifies the probability of accurately recognizing an object through its RGB-D Point Cloud at various viewpoints. Further a decision tree approach is used to formulate a optimal control plan. The framework has been tested on a kinect mounted on a robotic platform. Development in ROS, C++.</p>
      </div>

      <div class="col-md-5" align="center">
        <img src="static/img/iiit_proj.png" width="100%" style="margin-top: 100px;">
      </div>
    </div>

    <div class="row">
      <div class="col-md-7">
        <h3 class="content_heading">Charged Black holes in Constant Scalar Curvature f(R) Gravity</h3>
          <p class="">I worked under the guidance of <a href="http://mailweb.iacs.res.in/theoph/tpssg/">Dr. Soumitra Sengupta</a>.</p> 
          <p class="">I worked with Dr. Soumitra Sengupta with a focus towards searching for Charged Rotating Black Hole solutions in Einstein-Gauss-Bonnet dilaton coupled gravity. I studied and simulated the conditions for existence of multiple horizons in constant scalar curvature f(R) gravity and acquired results demonstrating the convergence of event and cosmological horizons in the same. As an interesting exercise, I also studied an axisymmetric black hole in constant scalar curvature f(R) gravity.</p>
          <p class=""><b>Report : </b><a href="https://drive.google.com/file/d/0BxMpUrO9U5eCSlBqaXJwWFMwU00/view?usp=sharing">Findings</a></p>
      </div>

      <div class="col-md-5" align="center">
        <img src="static/img/GR.png" width="90%" style="margin-top: 100px;">
      </div>
    </div>

    <div class="row">
      <div class="col-md-7">
        <h3 class="content_heading"><a target="_blank" href="https://www.facebook.com/AUV.DTU/">Autonomous Underwater Vehicle</a></h3>
          <!-- <p class="">I worked under the guidance of <a href="http://spie.org/profile/rsinha">Dr. R.K. Sinha</a>. As a part of the team, I worked in the underwater acoustics and control systems department.</p> -->
          <p class=""><b> Underwater Acoustics</b> - I developed a Passive SONAR system for 3D localization of a sound source underwater. I studied the feasibility of solutions of the hyperboloid formulation of the localization problem and developed and Implemented two Range Estimation Algorithms using TDOA (Time Difference of Arrival) Estimations. I also worked on the implementation of the method of spherical intersection for localization of sound sources. I developed and simulated an algorithm for localization in cylindrical coordinates using TDOA and Bearing Estimations.</a></p>
          <p class=""><b>Control Systems</b> - I developed a robust control algorithm for the Autonomous Underwater Vehicle. I worked on developing the Control Module to implement simultaneous PID loops to maintain the orientation of the AUV and developed GUIs to tune and adjust the PID parameters accordingly. On the technical front, I implemented the use of an Android phone as the IMU (Inertial Measurement Unit) using an application for Android operating System. The Android phone uses the UDP communication for sending and receiving data packets between itself and the single board computer.</p>
          <p class=""><b>Journal Paper : </b><a href="http://www.auvsifoundation.org/sites/default/files/Delhi_Tech_2014_RoboSub_Journal.pdf">AUVSI Robosub Journal DTU-AUV</a></p>
      </div>

      <div class="col-md-5" align="center">
        <img src="static/img/zyra.jpg" width="100%" style="margin-top: 100px;">
      </div>
    </div>

    <div class="row">
      <div class="col-md-7">
        <h3 class="content_heading">Evaluating VQA Models</a></h3>
          <p class=""><b>Undergraduate Major Project</b> under the guidance of <a href="http://www.dtu.ac.in/Web/Departments/Electrical/faculty/">Dr. Mini Sreejeth.</a></p>
          <p class="">I implemented several baseline Visual Question Answering (VQA) models and compared their performances.</p>
          <p class="">I started off building models to answerthe ’how many?’ questions and implemented a DeepDream-based qualitative experiment using GoogleNet to study the compositionality characteristics of counting models. Given a base image, used the DeepDream framework to generate images for a given class and studied the count variations of related classes</p>
          <p class="">Implemented the VQA - LSTM + CNN baseline model, Hierarchical Co-attention and subsequently the then state-of-the-art Multimodal Compact Bilinear Pooling VQA and Visual Grounding model in torch and prepared demonstrations using Django and PyTorch</p>
      </div>

      <div class="col-md-5" align="center">
        <img src="static/img/vqa.png" width="100%" style="margin-top: 100px;">
      </div>
    </div>

    <div class="row">
      <div class="col-md-7">
        <h3 class="content_heading">Multi-stage Scene Understanding Pipeline</a></h3>
          <p class=""><b>Undergraduate Minor Project</b> under the guidance of <a href="http://www.dtu.ac.in/Web/Departments/Electrical/faculty/">Dr. Mini Sreejeth.</a></p>
          <p class="">I implemented a multi-stage pipeline for scene understanding using Scene Classification and Video Magnification Techniques (Setup from CSAIL MIT) as a minor project during coursework. Different Stages included basic scene classification techniques using GIST features followed by superpixeling to detect and identify objects and using video magnification to study subtle movements</p>
      </div>

      <div class="col-md-5" align="center">
        <img src="static/img/surveillance.jpg" width="60%" style="margin-top: 60px;">
      </div>
    </div>
  </div>
